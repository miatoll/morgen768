<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Webcam Gesture Recognition with OpenCV.js</title>
    <!-- Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom styles for video and canvas layout */
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            margin: auto;
            border-radius: 0.75rem;
            overflow: hidden;
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        }
        /* Flip the video horizontally to make it a mirror */
        video {
            transform: scaleX(-1);
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Flip the canvas to match the video */
        }
    </style>
</head>
<body class="bg-gray-100 dark:bg-gray-900 text-gray-900 dark:text-gray-100 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-2xl text-center mb-8">
        <h1 class="text-3xl md:text-4xl font-bold text-blue-600 dark:text-blue-400">Hand Gesture Recognition</h1>
        <p class="text-lg text-gray-600 dark:text-gray-400 mt-2">Using OpenCV.js</p>
    </div>

    <!-- Status message area -->
    <div id="status" class="w-full max-w-2xl bg-yellow-100 dark:bg-yellow-800 border-l-4 border-yellow-500 text-yellow-700 dark:text-yellow-200 p-4 rounded-md mb-4" role="alert">
        <p class="font-bold">Status</p>
        <p id="status-text">Loading OpenCV.js, please wait...</p>
    </div>
    
    <!-- Main content area -->
    <div class="w-full max-w-2xl">
        <div class="video-container bg-gray-900">
            <!-- Video element to display webcam feed -->
            <video id="video" playsinline autoplay muted class="w-full h-auto"></video>
            <!-- Canvas element to draw the processed output -->
            <canvas id="outputCanvas"></canvas>
        </div>
    </div>

    <!-- Gesture display area -->
    <div id="gesture-output" class="mt-6 text-center bg-white dark:bg-gray-800 p-6 rounded-lg shadow-md w-full max-w-2xl">
        <h2 class="text-xl font-semibold text-gray-700 dark:text-gray-300 mb-2">Recognized Gesture</h2>
        <p id="gesture-text" class="text-4xl font-bold text-green-500 dark:text-green-400 transition-all duration-300">Show your hand</p>
    </div>

    <!-- OpenCV.js Script -->
    <script async src="https://docs.opencv.org/4.9.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>

    <script type="text/javascript">
        // Get DOM elements
        const video = document.getElementById('video');
        const outputCanvas = document.getElementById('outputCanvas');
        const gestureText = document.getElementById('gesture-text');
        const statusText = document.getElementById('status-text');
        const statusBox = document.getElementById('status');
        
        let streaming = false;
        let src, dst, gray, cap, contours, hierarchy;
        let fingerCount = 0;

        // This function will be called when OpenCV.js is loaded
        function onOpenCvReady() {
            statusText.textContent = 'OpenCV.js is ready.';
            statusBox.classList.remove('bg-yellow-100', 'border-yellow-500', 'text-yellow-700');
            statusBox.classList.add('bg-green-100', 'dark:bg-green-800', 'border-green-500', 'text-green-700', 'dark:text-green-200');
            startCamera();
        }

        // Function to start the camera and video processing
        function startCamera() {
            if (streaming) return;
            navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false })
                .then(function(stream) {
                    video.srcObject = stream;
                    video.play();
                })
                .catch(function(err) {
                    console.error("An error occurred: " + err);
                    statusText.textContent = "Error accessing camera. Please allow camera access and refresh.";
                    statusBox.classList.remove('bg-green-100', 'border-green-500', 'text-green-700');
                    statusBox.classList.add('bg-red-100', 'dark:bg-red-800', 'border-red-500', 'text-red-700', 'dark:text-red-200');
                });

            video.addEventListener('canplay', function(ev) {
                if (!streaming) {
                    const videoWidth = video.videoWidth;
                    const videoHeight = video.videoHeight;
                    video.setAttribute('width', videoWidth);
                    video.setAttribute('height', videoHeight);
                    outputCanvas.setAttribute('width', videoWidth);
                    outputCanvas.setAttribute('height', videoHeight);
                    streaming = true;

                    // Initialize OpenCV objects
                    src = new cv.Mat(videoHeight, videoWidth, cv.CV_8UC4);
                    dst = new cv.Mat(videoHeight, videoWidth, cv.CV_8UC1);
                    gray = new cv.Mat();
                    cap = new cv.VideoCapture(video);
                    contours = new cv.MatVector();
                    hierarchy = new cv.Mat();
                    
                    statusText.textContent = "Camera started. Show your hand to the camera.";
                    // Start the main processing loop
                    requestAnimationFrame(processVideo);
                }
            }, false);
        }

        // Main video processing loop
        function processVideo() {
            if (!streaming) { return; }
            
            try {
                // Start processing time
                const begin = Date.now();

                // 1. Capture a frame from the video
                cap.read(src);

                // 2. Convert to grayscale and apply threshold
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
                cv.threshold(gray, dst, 100, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);

                // 3. Find contours
                cv.findContours(dst, contours, hierarchy, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE);
                
                let largestContourIndex = -1;
                let maxArea = 0;
                // Find the largest contour (assumed to be the hand)
                for (let i = 0; i < contours.size(); ++i) {
                    let area = cv.contourArea(contours.get(i), false);
                    if (area > maxArea) {
                        maxArea = area;
                        largestContourIndex = i;
                    }
                }
                
                // Clear the canvas for drawing
                let ctx = outputCanvas.getContext('2d');
                ctx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
                
                fingerCount = 0; // Reset finger count each frame

                // 4. Process the largest contour if found
                if (largestContourIndex !== -1 && maxArea > 5000) { // Min area threshold
                    const handContour = contours.get(largestContourIndex);
                    
                    // Draw the hand contour
                    let color = new cv.Scalar(0, 255, 0, 255); // Green
                    cv.drawContours(src, contours, largestContourIndex, color, 2, cv.LINE_8, hierarchy, 100);

                    // 5. Find convex hull and convexity defects
                    let hull = new cv.Mat();
                    let defects = new cv.Mat();
                    cv.convexHull(handContour, hull, false, true);
                    cv.convexityDefects(handContour, hull, defects);
                    
                    // Draw the convex hull
                    let hullPoints = new cv.MatVector();
                    hullPoints.push_back(hull);
                    cv.drawContours(src, hullPoints, 0, new cv.Scalar(255, 0, 0, 255), 2);
                    hullPoints.delete();

                    // 6. Count fingers based on convexity defects
                    // Each defect is a point away from the hull, often between fingers
                    if (defects.rows > 0) {
                        for (let i = 0; i < defects.rows; ++i) {
                            let start = handContour.data32S[defects.data32S[i * 4] * 2];
                            let start_y = handContour.data32S[defects.data32S[i * 4] * 2 + 1];
                            let end = handContour.data32S[defects.data32S[i * 4 + 1] * 2];
                            let end_y = handContour.data32S[defects.data32S[i * 4 + 1] * 2 + 1];
                            let far = handContour.data32S[defects.data32S[i * 4 + 2] * 2];
                            let far_y = handContour.data32S[defects.data32S[i * 4 + 2] * 2 + 1];

                            let startPt = new cv.Point(start, start_y);
                            let endPt = new cv.Point(end, end_y);
                            let farPt = new cv.Point(far, far_y);
                            
                            // Calculate angle of the defect
                            let a = Math.sqrt(Math.pow(endPt.x - startPt.x, 2) + Math.pow(endPt.y - startPt.y, 2));
                            let b = Math.sqrt(Math.pow(farPt.x - startPt.x, 2) + Math.pow(farPt.y - startPt.y, 2));
                            let c = Math.sqrt(Math.pow(endPt.x - farPt.x, 2) + Math.pow(endPt.y - farPt.y, 2));
                            let angle = Math.acos((b * b + c * c - a * a) / (2 * b * c)) * 180 / Math.PI;

                            // If angle is less than 90 degrees, it's likely a space between fingers
                            if (angle < 90) {
                                fingerCount++;
                                // Draw a circle at the far point (between fingers)
                                cv.circle(src, farPt, 5, new cv.Scalar(0, 0, 255, 255), -1);
                            }
                        }
                    }
                    
                    // The number of fingers is usually defects + 1
                    // Adding some checks for common cases
                    if (fingerCount > 0) {
                        fingerCount++;
                    } else if (maxArea > 10000) { // Check for a fist or one finger
                       fingerCount = 1; // Simplified: could be a fist or 1 finger. We'll refine this.
                    }

                    // A simple check for a fist (might not have defects)
                    const aspectRatio = cv.boundingRect(handContour).width / cv.boundingRect(handContour).height;
                    if (fingerCount === 1 && aspectRatio > 0.8 && aspectRatio < 1.4) {
                         // Likely a fist if aspect ratio is close to 1 and defects are few
                        gestureText.textContent = "Fist âœŠ";
                    } else {
                        gestureText.textContent = `${fingerCount} Finger(s) ðŸ‘‹`;
                    }
                    
                    hull.delete();
                    defects.delete();
                } else {
                    gestureText.textContent = "Show your hand";
                }

                // Display the processed frame
                cv.imshow('outputCanvas', src);

            } catch (err) {
                console.error("OpenCV processing error: ", err);
            }

            // Schedule the next frame processing
            requestAnimationFrame(processVideo);
        }

        // Clean up when the user leaves the page
        window.onunload = () => {
            if (src) src.delete();
            if (dst) dst.delete();
            if (gray) gray.delete();
            if (contours) contours.delete();
            if (hierarchy) hierarchy.delete();
        };

    </script>

</body>
</html>
