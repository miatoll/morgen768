<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenCV.js Face & Smile Detection</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 720px;
            border-radius: 0.5rem;
            overflow: hidden;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        #video, #canvasOutput {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #canvasOutput {
            z-index: 10;
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl mx-auto text-center">
        <h1 class="text-3xl md:text-4xl font-bold mb-2">Real-Time Face & Smile Detection</h1>
        <p class="text-gray-400 mb-6">Using OpenCV.js. The box will turn green when you smile!</p>

        <div id="status" class="bg-gray-800 p-4 rounded-lg mb-6 text-left">
            <h2 class="font-semibold text-lg mb-2">Status</h2>
            <p id="status-text" class="text-gray-300">Initializing...</p>
        </div>

        <div class="video-container mx-auto" style="padding-top: 56.25%;"> <video id="video" playsinline autoplay muted></video>
            <canvas id="canvasOutput"></canvas>
        </div>

        <button id="startButton" class="mt-6 px-6 py-3 bg-blue-600 hover:bg-blue-700 text-white font-semibold rounded-lg shadow-md transition-transform transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed" disabled>
            Start Webcam
        </button>
    </div>

    <script async src="https://docs.opencv.org/4.5.4/opencv.js" onload="onOpenCvReady();"></script>

    <script type="text/javascript">
        // DOM Elements
        const video = document.getElementById('video');
        const canvasOutput = document.getElementById('canvasOutput');
        const canvasContext = canvasOutput.getContext('2d');
        const startButton = document.getElementById('startButton');
        const statusText = document.getElementById('status-text');

        let streaming = false;
        let cvReady = false;
        let faceCascade;
        let smileCascade;
        let cap;
        let src;
        let gray;
        let faces;
        let smiles;

        // --- 1. Initialization and Loading ---
        function updateStatus(text) {
            console.log(text);
            statusText.innerHTML = text;
        }

        function onOpenCvReady() {
            updateStatus('OpenCV.js is ready.');
            cvReady = true;
            startButton.disabled = false;
            loadClassifiers();
        }
        
        function loadClassifiers() {
            const utils = new Utils('status-text');
            
            updateStatus('Loading face model...');
            utils.createFileFromUrl('haarcascade_frontalface_default.xml', `https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml`, () => {
                faceCascade = new cv.CascadeClassifier();
                faceCascade.load('haarcascade_frontalface_default.xml');
                updateStatus('Face model loaded. Loading smile model...');
                
                utils.createFileFromUrl('haarcascade_smile.xml', `https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_smile.xml`, () => {
                    smileCascade = new cv.CascadeClassifier();
                    smileCascade.load('haarcascade_smile.xml');
                    updateStatus('All models loaded. You can now start the webcam.');
                });
            });
        }

        // --- 2. Webcam and Video Handling ---
        startButton.addEventListener('click', () => {
            if (streaming) return;
            if (!cvReady || !faceCascade || !smileCascade) {
                alert("Models are not ready yet. Please wait.");
                return;
            }

            updateStatus('Requesting webcam access...');
            navigator.mediaDevices.getUserMedia({ video: true, audio: false })
                .then(stream => {
                    video.srcObject = stream;
                    video.play();
                })
                .catch(err => {
                    updateStatus(`Error accessing webcam: ${err}`);
                    console.error("An error occurred: " + err);
                });
        });

        video.addEventListener('canplay', function() {
            if (!streaming) {
                const container = document.querySelector('.video-container');
                const w = container.clientWidth;
                const h = container.clientHeight;
                video.setAttribute('width', w);
                video.setAttribute('height', h);
                canvasOutput.setAttribute('width', w);
                canvasOutput.setAttribute('height', h);
                
                // Initialize OpenCV objects
                cap = new cv.VideoCapture(video);
                src = new cv.Mat(h, w, cv.CV_8UC4);
                gray = new cv.Mat(h, w, cv.CV_8UC1);
                faces = new cv.RectVector();
                smiles = new cv.RectVector();
                
                streaming = true;
                startButton.textContent = "Detection Running";
                startButton.disabled = true;
                requestAnimationFrame(processVideo);
            }
        }, false);

        // --- 3. Real-time Video Processing ---
        function processVideo() {
            if (!streaming) {
                // Clean up resources if streaming stops
                src.delete(); gray.delete(); faces.delete(); smiles.delete();
                return;
            }

            const startTime = performance.now();
            cap.read(src);
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
            
            try {
                // Detect faces
                faceCascade.detectMultiScale(gray, faces, 1.1, 5, 0);
            } catch (err) {
                console.error("Face detection error: ", err);
            }
            
            canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
            
            // Loop through detected faces
            for (let i = 0; i < faces.size(); ++i) {
                const faceRect = faces.get(i);
                let smiling = false;

                // Create a Region of Interest (ROI) for the face
                const faceROI = gray.roi(faceRect);
                
                try {
                    // In each face, detect smiles
                    // Tuning these parameters (1.8, 20) is key for smile detection
                    smileCascade.detectMultiScale(faceROI, smiles, 1.8, 20, 0); 
                    if (smiles.size() > 0) {
                        smiling = true;
                    }
                } catch (err) {
                    console.error("Smile detection error: ", err);
                }
                
                // Draw the face rectangle
                // Color it green if smiling, blue otherwise
                const color = smiling ? 'rgba(45, 212, 191, 0.9)' : 'rgba(59, 130, 246, 0.9)';
                canvasContext.strokeStyle = color;
                canvasContext.lineWidth = 3;
                canvasContext.strokeRect(faceRect.x, faceRect.y, faceRect.width, faceRect.height);

                if (smiling) {
                    canvasContext.fillStyle = color;
                    canvasContext.font = 'bold 18px Inter';
                    canvasContext.fillText('Smile!', faceRect.x, face-rect.y > 20 ? faceRect.y - 5 : faceRect.y + faceRect.height + 20);
                }

                // Clean up the ROI to prevent memory leaks
                faceROI.delete();
            }
            
            const endTime = performance.now();
            const fps = 1000 / (endTime - startTime);
            updateStatus(`Found ${faces.size()} faces. (FPS: ${fps.toFixed(1)})`);

            requestAnimationFrame(processVideo);
        }

        // --- Helper class for loading files ---
        function Utils(statusId) {
            this.statusElement = document.getElementById(statusId);
            this.createFileFromUrl = function(path, url, callback) {
                let request = new XMLHttpRequest();
                request.open('GET', url, true);
                request.responseType = 'arraybuffer';
                request.onload = (ev) => {
                    if (request.readyState === 4 && request.status === 200) {
                        let data = new Uint8Array(request.response);
                        cv.FS_createDataFile('/', path, data, true, false, false);
                        callback();
                    } else {
                        updateStatus(`Failed to load ${url}. Status: ${request.status}`);
                    }
                };
                request.send();
            };
        }
    </script>
</body>
</html>
